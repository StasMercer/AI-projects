{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-04T12:06:44.438737Z",
     "iopub.status.busy": "2020-09-04T12:06:44.437785Z",
     "iopub.status.idle": "2020-09-04T12:06:49.947925Z",
     "shell.execute_reply": "2020-09-04T12:06:49.946833Z"
    },
    "id": "bhrV98ildJZn",
    "papermill": {
     "duration": 5.527022,
     "end_time": "2020-09-04T12:06:49.948050",
     "exception": false,
     "start_time": "2020-09-04T12:06:44.421028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from enum import unique\n",
    "import json\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, GRU\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-04T12:06:49.970752Z",
     "iopub.status.busy": "2020-09-04T12:06:49.970038Z",
     "iopub.status.idle": "2020-09-04T12:06:50.002224Z",
     "shell.execute_reply": "2020-09-04T12:06:50.001560Z"
    },
    "id": "Ar70UAfddJZ1",
    "papermill": {
     "duration": 0.04498,
     "end_time": "2020-09-04T12:06:50.002383",
     "exception": false,
     "start_time": "2020-09-04T12:06:49.957403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../input/pacane/q.json\", \"r\", encoding='utf8') as read_file:\n",
    "    data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-04T12:06:50.043894Z",
     "iopub.status.busy": "2020-09-04T12:06:50.033587Z",
     "iopub.status.idle": "2020-09-04T12:06:50.561408Z",
     "shell.execute_reply": "2020-09-04T12:06:50.562402Z"
    },
    "papermill": {
     "duration": 0.550867,
     "end_time": "2020-09-04T12:06:50.562623",
     "exception": false,
     "start_time": "2020-09-04T12:06:50.011756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_words = 5000\n",
    "oov_token = '<UNK>'\n",
    "pad_type = 'post'\n",
    "trunc_type = 'post'\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(data)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(data)\n",
    "maxlen = max([len(x) for x in train_sequences])\n",
    "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-04T12:06:50.604852Z",
     "iopub.status.busy": "2020-09-04T12:06:50.603958Z",
     "iopub.status.idle": "2020-09-04T12:06:53.253114Z",
     "shell.execute_reply": "2020-09-04T12:06:53.252338Z"
    },
    "id": "vk4F3HOJdJaB",
    "outputId": "9fe86a07-070f-4be3-84f9-69f947ee4f62",
    "papermill": {
     "duration": 2.677429,
     "end_time": "2020-09-04T12:06:53.253238",
     "exception": false,
     "start_time": "2020-09-04T12:06:50.575809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 inp, 8460 words\n",
      "[[   5   28  151 ...    0    0    0]\n",
      " [  11  298 3183 ...    0    0    0]\n",
      " [  36   15  872 ...    0    0    0]\n",
      " ...\n",
      " [   7   29  415 ...    0    0    0]\n",
      " [ 396    4    2 ...    0    0    0]\n",
      " [   3   37  417 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_len = maxlen\n",
    "words_len = len(word_index.keys())\n",
    "print(f\"{input_len} inp, {words_len} words\")\n",
    "\n",
    "# I started to use tf dataset to simplify the process\n",
    "# First it got a all text as list of numbers\n",
    "print(train_padded)\n",
    "input_dataset = tf.data.Dataset.from_tensor_slices(train_padded)\n",
    "seq_length = maxlen+1\n",
    "\n",
    "# now it holds tuples ((seq_length), (seq_length)) where first is x, second is y\n",
    "def split_input_target(chunk):\n",
    "  input_text = chunk[:-1]\n",
    "  target_text = chunk[1:]\n",
    "  return input_text, target_text\n",
    "dataset = input_dataset.map(split_input_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-04T12:06:53.278257Z",
     "iopub.status.busy": "2020-09-04T12:06:53.277509Z",
     "iopub.status.idle": "2020-09-04T12:06:53.290467Z",
     "shell.execute_reply": "2020-09-04T12:06:53.289745Z"
    },
    "id": "z3L-ICwSdJaT",
    "papermill": {
     "duration": 0.027194,
     "end_time": "2020-09-04T12:06:53.290597",
     "exception": false,
     "start_time": "2020-09-04T12:06:53.263403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((16, 194), (16, 194)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "# shuffle and split to batches again\n",
    "batch_size = 16\n",
    "embedding_dim = 54\n",
    "rnn_units = 128\n",
    "\n",
    "dataset = dataset.shuffle(1000).batch(batch_size, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-04T12:06:53.317603Z",
     "iopub.status.busy": "2020-09-04T12:06:53.316869Z",
     "iopub.status.idle": "2020-09-04T12:06:53.321165Z",
     "shell.execute_reply": "2020-09-04T12:06:53.320629Z"
    },
    "papermill": {
     "duration": 0.020155,
     "end_time": "2020-09-04T12:06:53.321272",
     "exception": false,
     "start_time": "2020-09-04T12:06:53.301117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(words_len, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(words_len, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True),\n",
    "    tf.keras.layers.Dense(words_len)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-04T12:06:53.348814Z",
     "iopub.status.busy": "2020-09-04T12:06:53.348132Z",
     "iopub.status.idle": "2020-09-04T12:06:54.111651Z",
     "shell.execute_reply": "2020-09-04T12:06:54.112152Z"
    },
    "id": "vJdlK7r2dJal",
    "outputId": "d5b8b71e-0a92-437a-9595-ee48ef88385b",
    "papermill": {
     "duration": 0.780456,
     "end_time": "2020-09-04T12:06:54.112322",
     "exception": false,
     "start_time": "2020-09-04T12:06:53.331866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_model(words_len, embedding_dim, rnn_units, batch_size)\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-04T12:06:54.137429Z",
     "iopub.status.busy": "2020-09-04T12:06:54.136447Z",
     "iopub.status.idle": "2020-09-04T12:07:48.638703Z",
     "shell.execute_reply": "2020-09-04T12:07:48.637973Z"
    },
    "id": "AjJyyNeXdJa0",
    "outputId": "f734d4d4-3dc0-4765-9ad2-c09e97637801",
    "papermill": {
     "duration": 54.515626,
     "end_time": "2020-09-04T12:07:48.638844",
     "exception": false,
     "start_time": "2020-09-04T12:06:54.123218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "623/623 [==============================] - 22s 36ms/step - loss: 0.7119 - accuracy: 0.9615\n",
      "Epoch 2/2\n",
      "623/623 [==============================] - 22s 36ms/step - loss: 0.2749 - accuracy: 0.9637\n"
     ]
    }
   ],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "\n",
    "model.fit(dataset, epochs=2, callbacks=[checkpoint_callback])\n",
    "model.save('model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-04T12:07:49.139115Z",
     "iopub.status.busy": "2020-09-04T12:07:49.138047Z",
     "iopub.status.idle": "2020-09-04T12:07:54.087839Z",
     "shell.execute_reply": "2020-09-04T12:07:54.071500Z"
    },
    "papermill": {
     "duration": 5.202337,
     "end_time": "2020-09-04T12:07:54.087981",
     "exception": false,
     "start_time": "2020-09-04T12:07:48.885644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_model(words_len, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.save('/model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-04T12:07:54.576873Z",
     "iopub.status.busy": "2020-09-04T12:07:54.575876Z",
     "iopub.status.idle": "2020-09-04T12:07:54.685441Z",
     "shell.execute_reply": "2020-09-04T12:07:54.686194Z"
    },
    "id": "P2mvI-agdJa6",
    "papermill": {
     "duration": 0.36178,
     "end_time": "2020-09-04T12:07:54.686367",
     "exception": false,
     "start_time": "2020-09-04T12:07:54.324587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ваше анон тишина объясняй —во слабостью наша унас называла прекрасен пять рулю похоронить приняли была оценок вернется прекрасном настоящего миру\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "    num_generate = 20\n",
    "    \n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = start_string\n",
    "    \n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "  # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "    temperature = 0.4\n",
    "\n",
    "  # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "    # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "    # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "    # We pass the predicted character as the next input to the model\n",
    "    # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(predicted_id)\n",
    "    \n",
    "    idx2word = np.array(list(word_index.keys()))\n",
    "    return ( ' '.join([idx2word[i] for i in text_generated]))\n",
    "print(generate_text(model, [word_index['когда']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.234329,
     "end_time": "2020-09-04T12:07:55.155117",
     "exception": false,
     "start_time": "2020-09-04T12:07:54.920788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 76.905355,
   "end_time": "2020-09-04T12:07:56.995130",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-04T12:06:40.089775",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
